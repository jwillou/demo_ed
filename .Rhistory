tt   = tt[tt>0]
fams = c(fams, length(tt))
spp  = c(spp, nrow(temp))
}
cbind(classes, fams, spp)
install.packages("lme4")
####don't do residulas, do random effect for study for the intercept then move on with life (fixed effects for everything else)
library(lme4)
?length
length(data$t, na.rm=T)
y=1:9
dim(y)=c(3,3)
str(y)
y
?upper.diag
?power.anova.test
?as.logical
NA/1
?matrix
a=3
b=4
a|b
a=0
b=0
a|b
sample(1, 1:20, replace=T)
t=20
sum(sample(t, 1:20, replace=T))
sum(sample(1:20,t, replace=T))
t=15
sum(sample(1:20,t, replace=T))
t=10
sum(sample(1:20,t, replace=T))
t=
sum(sample(1:20,t, replace=T))
t=10
sum(sample(1:20,t, replace=T))
sum(sample(1:20,t, replace=T))
t=11
sum(sample(1:20,t, replace=T))
t=11
sum(sample(1:20,t, replace=T))
t=11
sum(sample(1:20,t, replace=T))
t=10
sum(sample(1:20,t, replace=T))
t=9
sum(sample(1:20,t, replace=T))
t=10
sum(sample(1:20,t, replace=T))
dice = 7
sum(sample(c(1,2,3,4), dice, replace=T)+(dice))
sample(c(1,2,3,4), dice, replace=T)
(dice)
sample(c(1,2,3,4), dice, replace=T)+(dice)
sum(sample(c(1,2,3,4), dice, replace=T))+(dice)
sum(sample(c(1,2,3,4), dice, replace=T))+(dice)
sum(sample(c(1,2,3,4), dice, replace=T))+(dice)
sum(sample(1:4, dice, replace=T))+(dice)
#fireball 8d6
sum(sample(1:8, 6, replace=T))
#fireball 8d6
sum(sample(1:8, 6, replace=T))
#fireball 8d6
sum(sample(1:8, 6, replace=T))
#magic missle (3d4+1 @4th lvl, +1 die per level)
dice = 7
sum(sample(1:4, dice, replace=T))+(dice)
#magic missle (3d4+1 @4th lvl, +1 die per level)
dice = 5
sum(sample(1:4, dice, replace=T))+(dice)
sample(1:20,1) #magic surge
sample(1:20,1) #magic surge
paste(sample(seq(0,100,10),1), sample(1:10,1), sep="")
paste(sample(1:10,1), sample(1:10,1), sep="")
paste(sample(0:9,1), sample(1:9,1), sep="")
sample(1:100,1)
sample(1:100,1)
#magic missle (3d4+1 @4th lvl, +1 die per level)
dice = 7
sum(sample(1:4, dice, replace=T))+(dice)
sample(1:20,1) #magic surge
sample(1:100,1)
#heal
(sample(1:6,1)+1)*2
#heal
(sample(1:6,1)+1)*2
#heal
(sample(1:6,1)+1)*2
#heal
(sample(1:6,1)+1)*2
#heal
sumrep(((sample(1:6,1)+1)*2),2))
#heal
sum(rep(((sample(1:6,1)+1)*2),2))
rep(((sample(1:6,1)+1)*2),2)
sample(1:6,1)+1)*2
sample(1:6,1)+1)*2)
sample(1:6,1)
sample(1:6,1)+1
(sample(1:6,1)+1)*2)
(sample(1:6,1)+1)*2
((sample(1:6,1)+1)*2)
rep(((sample(1:6,1)+1)*2),2)
replicate(((sample(1:6,1)+1)*2),2)
(sample(1:6,1)+1)*2
(sample(1:6,1)+1)*2
?replicate
#heal
sample(1:6,2)+1)*2)
#heal
sample(1:6,2)+1)*2
#heal
(sample(1:6,2)+1)*2
#heal
sum(c((sample(1:6,2)+1)*2))
c((sample(1:6,2)+1)*2)
c((sample(1:6,2)+1)*2)
c((sample(1:6,2)+1)*2)
c((sample(1:6,2)+1)*2)
c((sample(1:6,2)+1)*2)
#heal
npotions = 1
sum(c((sample(1:6,2)+npotions)*2))
sum(c((sample(1:6,2)+npotions)*2))
sum(c((sample(1:6,npotions)+1)*2))
sample(1:8,npotions)
sample(1:8,npotions)
#heal - doubled because of necklace
npotions = 5
sum(sample(1:8,npotions))
sum(sample(1:8,npotions))
sample(1:8,npotions)
#heal - doubled because of necklace
npotions = 5
sum(c((sample(1:6,npotions)+1)*2))
#heal - doubled because of necklace
npotions = 2
sum(c((sample(1:6,npotions)+1)*2))
#fireball 8d6
sum(sample(1:8, 6, replace=T))
sample(1:20,1) #magic surge
sample(1:20,1) #magic surge
sample(1:100,1)
#heal - doubled because of necklace
npotions = 1
sum(c((sample(1:6, replace=T, npotions)+1)*2))
#magic missle (3d4+1 @4th lvl, +1 die per level)
dice = 8
sum(sample(1:4, dice, replace=T))+(dice)
sample(1:20,1) #magic surge
sample(1:100,1)
sum(sample(1:4, dice, replace=T))+(dice)
sample(1:20,1) #magic surge
sample(1:100,1)
sum(c(sample(1:6, dice, replace=T),(dice*1))
)
sum(c(sample(1:6, dice, replace=T),(dice*1)))*2
sum(c(sample(1:6, dice, replace=T),(dice*1)))*2
sample(1:6, dice, replace=T)
#short rest - doubled because of necklace
dice = 1
sum(c(sample(1:6, dice, replace=T),(dice*1)))*2
sum(c(sample(1:6, dice, replace=T),(dice*1)))*2
#short rest - doubled because of necklace
dice = 2
sum(c(sample(1:6, dice, replace=T),(dice*1)))*2
sample(c(1:6), replace=T, n=25)
sample(c(1:6), 25, replace=T)
table(sample(c(1:6), 25, replace=T))
table(sample(c(1:6), 50, replace=T))
sample(c(1:8),1,replace=T)+4
sample(c(1:8),1,replace=T)+4
rep((sample(c(1:8),1,replace=T)+4),5)
sum(rep((sample(c(1:8),1,replace=T)+4),5))
sum(rep((sample(c(1:8),5,replace=T)+5),5))
n=5
sum(rep((sample(c(1:8),n,replace=T)+n),1))
sum(rep((sample(c(1:8),n,replace=T)+n),1))
n=i=null
n=i=NULL
n=i=NULL
while(n<75)(
i = i+1
n = n + sample(c(1:8),n,replace=T)+4
n=i=NULL
while(n<75)(
i = i+1
n = n + sample(c(1:8),1) + 4
n=0
i=NULL
while(n<75)(
i = i+1
n = n + sample(c(1:8),1) + 4
n=0
i=NULL
while(n<75){
i = i+1
n = n + sample(c(1:8),1) + 4
}
i
n=0
i=0
while(n<75){
i = i+1
n = n + sample(c(1:8),1) + 4
}
n=0
i=0
while(n<75){
i = i+1
n = n + sample(c(1:8),1) + 4
}
n=0
i=0
while(n<75){
i = i+1
n = n + sample(c(1:8),1) + 4
}
n=0
i=0
while(n<75){
i = i+1
n = n + sample(c(1:8),1) + 4
}
n=0
i=0
while(n<75){
i = i+1
n = n + sample(c(1:8),1) + 4
}
for(n in 1:1000){
n=0
i=0
while(n<75){
i = i+1
n = n + sample(c(1:8),1) + 4
}
ii = c(ii,i)}
ii=NULL
for(n in 1:1000){
n=0
i=0
ii=NULL
while(n<75){
i = i+1
n = n + sample(c(1:8),1) + 4
}
ii = c(ii,i)}
hist(ii)
ii
for(n in 1:1000){
n=0
i=0
ii=NULL
while(n<75){
i = i+1
n = n + sample(c(1:8),1) + 4
}
ii = c(ii,i)
}
ii
ii
for(nn in 1:1000){
n=0
i=0
ii=NULL
while(n<75){
i = i+1
n = n + sample(c(1:8),1) + 4
}
ii = c(ii,i)
}
i
ii
ii=NULL
ii=NULL
for(nn in 1:1000){
n=0
i=0
while(n<75){
i = i+1
n = n + sample(c(1:8),1) + 4
}
ii = c(ii,i)
}
hist(ii)
for(nn in 1:10000){
n=0
i=0
while(n<75){
i = i+1
n = n + sample(c(1:8),1) + 4
}
ii = c(ii,i)
}
hist(ii)
hist(ii, main="number of roles to get >75")
hist(ii, main="number of roles to get >75", xlab="number of roles")
#chatbook
hitpoints = 75
?
map
library(maps)
library(dplyr)
library(geosphere)
library(scales)
?map
citation('maps')
install.packages("metafor")
?escala
library(metafor)
?escala
?escalc
setwd("/Users/jannawilloughby/Google Drive/My Drive/Willoughby lab/projects - active/dolphins and turtles/demography_ed/")
data = read.table("Cleaned up Coastal Tourist Combined Data - R.data CLEAN.csv", header=T, sep=",")
View(data)
head(data)
# CSV columns are named "Race", "Gender", and "Education"
race_values <- na.omit(unique(raw_data$Race))
# Load raw data from the CSV file
raw_data <- read.table("Cleaned up Coastal Tourist Combined Data - R.data CLEAN.csv", header=T, sep=",") #read.csv(file.choose())
# CSV columns are named "Race", "Gender", and "Education"
race_values <- na.omit(unique(raw_data$Race))
gender_values <- na.omit(unique(raw_data$Gender))
education_values <- na.omit(unique(raw_data$Education))
# Calculate nested proportions for all combinations in raw data
nested_counts <- list() #This counts all the possible proportions
for (gender in gender_values) {
for (race in race_values) {
for (edu in education_values) {
count <- sum(!is.na(raw_data$Gender) & !is.na(raw_data$Race) & !is.na(raw_data$Education) &
raw_data$Gender == gender & raw_data$Race == race & raw_data$Education == edu)
nested_counts[[paste(gender, race, edu)]] <- count
}
}
}
# Function to generate population based on nested proportions and adjust for rounding discrepancies
generate_population <- function(size, counts) {
total_counts <- sum(unlist(counts))
scaling_factor <- size / total_counts
generated_population <- data.frame()
remaining_individuals <- size
for (gender in gender_values) {
for (race in race_values) {
for (edu in education_values) {
# Calculate the number of individuals for each combination and adjust for rounding discrepancies
count <- round(counts[[paste(gender, race, edu)]] * scaling_factor)
individuals <- data.frame(
gender = rep(gender, count),
race = rep(race, count),
education = rep(edu, count)
)
# Update remaining individuals after rounding
remaining_individuals <- remaining_individuals - count
# Combine generated individuals into the population dataframe
generated_population <- rbind(generated_population, individuals)
}
}
}
# Distribute remaining individuals based on rounding differences
if (remaining_individuals > 0) {
extra_individuals <- raw_data[sample(nrow(raw_data), remaining_individuals), ]
generated_population <- rbind(generated_population, extra_individuals)
}
return(generated_population)
}
# Function to calculate proportions in the generated population
calculate_generated_proportions <- function(population) {
return(prop.table(table(population$race, population$gender, population$education)))
}
# Generate population using the nested proportions and adjusted rounding
population_size <- 1000  # Adjust as needed
population <- generate_population(population_size, nested_counts)
View(population)
data = read.table("Cleaned up Coastal Tourist Combined Data - R.data CLEAN.csv", header=T, sep=",")
#Set working directory and out directory
setwd("/Users/jannawilloughby/Google Drive/My Drive/Willoughby lab/projects - active/dolphins and turtles/demography_ed/")
directory = getwd()
outdir = paste(directory, "/Output/", sep = "")   #  outdir = paste("C:/Users/ginab/Box/New Computer/Auburn/Data/ComplexModel_ABM", "/Output_local/", sep = "")
#source functions
source(paste(getwd(), "/RunModel.R", sep = ''))
#source functions
source(paste(getwd(), "Source/RunModel.R", sep = ''))
#source functions
source(paste(getwd(), "/Source/RunModel.R", sep = ''))
#source functions
source(paste(getwd(), "/Source/RunModel.R", sep = ''))
setwd("/Users/jannawilloughby/Google Drive/My Drive/Willoughby lab/projects - active/dolphins and turtles/demography_ed/")
#source functions
source(paste(getwd(), "/Source/RunModel.R", sep = ''))
#Set working directory and out directory
setwd("/Users/jannawilloughby/Google Drive/My Drive/Willoughby lab/projects - active/dolphins and turtles/demography_ed/")
directory = getwd()
outdir = paste(directory, "Output/", sep = "")
#Source function scripts
source(paste(directory, "/Source/FunctionSourcer.R", sep = ''))
#Source function scripts
source(paste(directory, "Source/FunctionSourcer.R", sep = ''))
#set working directory, import packages, source functions,
setwd(paste(directory,"/Source/", sep = '')) #set temp working directory
#call installed libraries
#library(reshape2)    #need this for plotting
library(scales)      #need this for plotting, this allows transparency in colors for overlapping lines
#source functions
source(paste(getwd(), "RunModel.R", sep = ''))
#source functions
source(paste(getwd(), "RunModel.R", sep = ''))
#source functions
source(paste(getwd(), "/RunModel.R", sep = ''))
#Set working directory and out directory
setwd("/Users/jannawilloughby/Google Drive/My Drive/Willoughby lab/projects - active/dolphins and turtles/demography_ed/")
directory = getwd()
outdir = paste(directory, "Output/", sep = "")
#Source function scripts
source(paste(directory, "Source/FunctionSourcer.R", sep = ''))
#Source function scripts
source(paste(directory, "/Source/FunctionSourcer.R", sep = ''))
#source functions
source(paste(getwd(), "/FunctionSourcer.R", sep = ''))
#source functions
source(paste(getwd(), "/Source/FunctionSourcer.R", sep = ''))
#Source function scripts
source(paste(directory, "/Source/FunctionSourcer.R", sep = ''))
#Source function scripts
source(paste(directory, "/Source/FunctionSourcer.R", sep = ''))
#source functions
source(paste(getwd(), "/Source/RunModel.R", sep = ''))
data = read.table("Input/Cleaned up Coastal Tourist Combined Data - modified codes test.csv", header=T, sep=",")
survey_data = read.table("Input/Cleaned up Coastal Tourist Combined Data - modified codes test.csv", header=T, sep=",")
# Create agents from survey data
agents <- survey_data
# Example scenarios
scenarios <- list(
baseline = list(
outreach_intensity = c(1, 2, 3),
demographic_shift = 0
),
high_outreach = list(
outreach_intensity = c(2, 4, 6),
demographic_shift = 0
),
demographic_shift = list(
outreach_intensity = c(1, 2, 3),
demographic_shift = 0.1 # 10% increase in population segment
)
)
scenarios
View(scenarios)
# Load necessary data
survey_data = read.table("Input/Cleaned up Coastal Tourist Combined Data - modified codes test.csv", header=T, sep=",")
# Create agents from survey data
agents <- survey_data
# Example scenarios in a data frame
scenarios <- data.frame(
scenario = c("baseline", "high_outreach", "demographic_shift"),
outreach_intensity_1 = c(1, 2, 1),
outreach_intensity_2 = c(2, 4, 2),
outreach_intensity_3 = c(3, 6, 3),
demographic_shift = c(0, 0, 0.1)
)
scenarios
head(agents)
scenarios
# Example scenarios in a data frame (will come from cover eventually)
scenarios <- data.frame(
scenario = c("outreach", "demographic_shift"),
outreach = c(1, 2, 1),
demographic_shift = c(0, 0, 0.1)
)
# Example scenarios in a data frame (will come from cover eventually)
scenarios <- data.frame(
outreach = c(1, 2, 1),
demographic_shift = c(0, 0, 0.1)
)
colnames(scenarios) = c("outreach", "demographic_shift")
scenarios
head(agents)
agents[,agents$Policy:agents$Wildlife]
dim(agents)
agents[,17:18]
apply(agents[,17:18],1,mean, na.rm=T)
agent$knowledge_level = apply(agents[,17:18],1,mean, na.rm=T) #mean of policy and wildlife knowledge
agents$knowledge_level = apply(agents[,17:18],1,mean, na.rm=T) #mean of policy and wildlife knowledge
scenarios = expand.grid(outreach_efforts.P, outreach_method.P, demographic_shift.P)
#Set scenarios
outreach_efforts.P  = c(1, 2, 3)                                         #Number of new outreach items produced annually
outreach_method.P   = c("Pamphlet", "Sign", "Magnet", "Sticker")         #Outreach media that will be used
demographic_shift.P = c("Age10", "IncreaseHispanic")                     #These will need to be defined, not sure what we want
scenarios = expand.grid(outreach_efforts.P, outreach_method.P, demographic_shift.P)
scenarios
remove(outreach_efforts.P, outreach_method.P, demographic_shift.P)
colnames(scenarios) = c("outreach_efforts", "outreach_method", "demographic_shift")
scenarios
rr=i=1
head(scenarios)
outreach_efforts  = scenarios$outreach_efforts[,i]
outreach_method   = scenarios$outreach_method[,i]
outreach_efforts  = scenarios$outreach_efforts[i]
outreach_method   = scenarios$outreach_method[i]
demographic_shift = scenarios$demographic_shift[i]
#start with a fresh set of individuals
rragents = agents
head(rragents)
outreach_efforts
y=1
y%1
mod(1,1)
1 %% 1
1 %% 2
2 %% 1
(y %% outreach_efforts) == 0
